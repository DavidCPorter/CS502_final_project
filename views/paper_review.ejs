<!DOCTYPE html>
<html lang="en">
  <!-- header -->
  <% include ./_header %>

  <!-- NAVBAR-->
  <% include ./_nav %>

  <!--===============================================================-->

  <!-- INTRO-->

  <body data-spy="scroll" data-target=".scroll-bootstrap" data-offset="50">


  <div style="padding:20px;padding-top:100px;">
    <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;"><strong><span style="font-size: 14.5pt; font-family: Arial; color: #000000; background-color: transparent; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Bayesian Multiple Protein Structure Alignment</span></strong></p>
    <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;"><span style="font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Rui Wang and Scott C. Schmidler</span></p><br>
    <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;"><strong><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Paper Summary</span></strong></p>
    <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; text-indent: 36pt;"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">This paper develops and analyzes a probabilistic model-based approach to multiple structural alignment. &nbsp;Structural alignment is key to understanding protein functionality, and is fundamental to how we understand sequence alignment in proteins. At first blush, the sequence and structural alignment task may seem like two sides of the same coin, and that&rsquo;s not too far from the truth, however, structural alignment is a problem riddled with more uncertainty due to the dynamic nature of these protein structures. Structural variability makes protein alignment very challenging, and necessitates more generality in the alignment algorithms when compared to popular sequence alignment algorithms. The authors believe that a probabilistic model-based approach is appropriate for the problem at hand due to the uncertainty that naturally arises from the stochasticity of the underlying model in sequence alignment, limited information contained in the sequences themselves, and sensitivity to algorithm parameters (such as optimization metric or gap penalty). &nbsp;They note that choice of optimization &shy;metric allows potential for bias and different choices often drastically affect the outcome. Hence they develop an approach that leverages the probabilistic framework associated with Hidden Markov Models (HMMs) to statistically model the shape of the protein, and combined this with the more traditional methods in sequence alignment algorithms to predict protein alignment more accurately. This allows </span><em><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">the algorithm</span></em><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"> rather than the user to select model parameters as well as derive an optimal solution to the problem simultaneously.</span></p>
    <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; text-indent: 36pt;"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">The core of the model is the assumption that the structures are generated from a hidden distribution, and Bayesian inference is used to learn the model. &nbsp;The states that the HMM is allowed to transition to/from are match, insert and delete, with a unique feature of this model being that matches and insertions are done based on gaussian distributions rather than simply selecting a letter from a nucleotide or amino acid&mdash;resulting in a probability vector rather than a label. The traditional HMM techniques fail when modeling 3D coordinates since the conditional independence structure is broken when factoring rotation and translation of coordinates on a 3D plane. This is why the structural alignment algorithms were implemented using an iterative sampling scheme for probabilistic inference using joint distributions. Model parameters are estimated along with the model itself, which the authors claim has the following benefits:</span></p>
    <ul style="margin-top: 0pt; margin-bottom: 0pt;">
    <li style="list-style-type: disc; font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Allows for better comparison of drastically dissimilar structures, or evolutionarily dissimilar entities</span></li>
    <li style="list-style-type: disc; font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Improves model accuracy (validated in the results section)</span></li>
    <li style="list-style-type: disc; font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Assists in preventing the sampling method (MCMC) from getting trapped</span></li>
    <li style="list-style-type: disc; font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Is able to assign state transition probabilities (probability of transitioning from a match to an insertion for instance).</span></li>
    <li style="list-style-type: disc; font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre;"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">The model simultaneously prevents an insertion followed by a deletion or visa versa by setting those probabilities to 0. &nbsp;Insertion followed by deletion would have no effect so, it was manually prohibited.</span></li>
    </ul>
    <p>&nbsp;</p>
    <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; text-indent: 36pt;"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">The model was evaluated by comparing it to other well-known multiple sequence alignment algorithms using a set of difficult sequencing tasks. &nbsp;First, eight KH-domain type I structures from SISYPHUS were taken and run through this algorithm, MUSTANG, MATT and POSA. All algorithms were compared to a human-created-alignment and the probabilistic HMM algorithm had near perfect match to the human alignment. &nbsp;The others had issues due to the lack of probabilistic nature and the inability to assess state transition probability. Next, a difficult case of comparing 5 E. Coli strings with a single M. Tuberculosis string was performed. This test was shown to throw off common alignment algorithms, however the probabilistic model again performed the appropriate insertions to generate a valid alignment of the 6 strings. &nbsp;Finally, trees were constructed using the same algorithms from the first experiment to show clusterings of different animals based on Hemoglobin Subunit &alpha; similarity. And again, the probabilistic model was the only one to correctly group together mammals, reptiles, and birds as well as distinguish bony and non-bony fish.</span></p>
    <p>&nbsp;</p>
    <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;"><strong><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Group Commentary</span></strong></p>
    <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; text-indent: 36pt;"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">The inclusion of a probabilistic element to the problem of multiple structural alignment seems to address some of the underlying biological assumptions that cause other algorithms to fail to derive a biologically feasible alignment. &nbsp;It also automatically provides a &ldquo;confidence&rdquo; metric about the matching. So it would be possible to for instance say that the algorithm is 40% sure that the next letter should be G, which may assist in determine the confidence that someone has a disease for instance.</span></p>
    <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; text-indent: 36pt;"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Consistent with other higher-fidelity models, the run time for training this model would be prohibitive in large data sets. &nbsp;The authors reported that for a reasonable data set the model ran in 5-7 days on a distributed framework. For a really massive problem this approach probably wouldn&rsquo;t scale that well.</span></p>
    <p><br /><br /></p>
  </div>
  </body>
</html>
